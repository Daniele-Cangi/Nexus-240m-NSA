{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c668dfb4",
   "metadata": {},
   "source": [
    "# NEXUS‑EMB‑240M‑NSA — Colab Starter\n",
    "Edge‑first dual‑head embeddings with **Neural Spectral Anchoring** (NSA) and Residual Hashing Bridge.\n",
    "\n",
    "Follow the cells top‑to‑bottom. All training/eval instructions are in **English** to keep the training side consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00431cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime setup\n",
    "!pip -q install torch==2.4.0 transformers==4.44.2 sentencepiece==0.2.0 einops==0.8.0 \\\n",
    "           faiss-cpu==1.8.0.post1 onnxruntime-gpu==1.19.2 accelerate==0.34.2 bitsandbytes==0.43.3\n",
    "print(\"Environment ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the ZIP you downloaded from ChatGPT ('nexus_emb_240m_nsa.zip')\n",
    "from google.colab import files\n",
    "up = files.upload()\n",
    "zip_name = next(iter(up.keys()))\n",
    "print(\"Uploaded:\", zip_name)\n",
    "\n",
    "import os, zipfile\n",
    "target_dir = \"/content\"\n",
    "with zipfile.ZipFile(zip_name, 'r') as z:\n",
    "    z.extractall(target_dir)\n",
    "print(\"Extracted to:\", target_dir)\n",
    "\n",
    "# Find repo root\n",
    "import glob\n",
    "candidates = glob.glob(\"/content/**/nexus_emb_240m_nsa\", recursive=True)\n",
    "repo_root = candidates[0] if candidates else \"/content/nexus_emb_240m_nsa\"\n",
    "print(\"Repo root:\", repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d79dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files\n",
    "import os, subprocess, textwrap, json\n",
    "!ls -R \"$repo_root\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12c72a3",
   "metadata": {},
   "source": [
    "## 1) Train SentencePiece tokenizer (48k)\n",
    "Replace `demo.txt` with your own corpus manifests when ready.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b95d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "corpus_dir = Path(\"/content/corpus\"); corpus_dir.mkdir(parents=True, exist_ok=True)\n",
    "demo_text = \"\\n\".join([\n",
    "  \"This is a small demo corpus for tokenizer bootstrap.\",\n",
    "  \"BTC price action and mempool dynamics matter.\",\n",
    "  \"ENTSO-E grid load datasets power RAG pipelines.\",\n",
    "  \"JVL EtherCAT ROS2 robotics integration notes.\"\n",
    "]*2000)\n",
    "(corpus_dir/\"demo.txt\").write_text(demo_text)\n",
    "\n",
    "# Train tokenizer\n",
    "!python \"$repo_root/scripts/build_tokenizer.py\" --corpus \"/content/corpus/demo.txt\" --vocab 48000 --out_prefix \"/content/tokenizer_spm_48k\"\n",
    "print(\"Tokenizer artifacts at /content/tokenizer_spm_48k.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af2233",
   "metadata": {},
   "source": [
    "## 2) Bootstrap training\n",
    "Uses the included `data/demo_pairs.jsonl`. Replace with your mined pairs later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed222265",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = f\"{repo_root}/configs/nexus_emb_240m.json\"\n",
    "PAIRS = f\"{repo_root}/data/demo_pairs.jsonl\"\n",
    "SPM = \"/content/tokenizer_spm_48k.model\"\n",
    "\n",
    "!python \"$repo_root/scripts/train.py\" \\\n",
    "  --config \"$CFG\" \\\n",
    "  --pairs \"$PAIRS\" \\\n",
    "  --tokenizer_model \"$SPM\" \\\n",
    "  --batch 64 --max_len 128 --steps 1000 --lr 2e-3 --wd 0.05 --save_dir \"/content/ckpts\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdc420d",
   "metadata": {},
   "source": [
    "## 3) Tiny evaluation (sanity check)\n",
    "Just checks that positive pairs are closer than random negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92eb2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python \"$repo_root/scripts/eval_mteb_lite.py\" \\\n",
    "  --config \"$CFG\" \\\n",
    "  --tokenizer_model \"$SPM\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d226f3d",
   "metadata": {},
   "source": [
    "## 4) Export ONNX (int8‑ready)\n",
    "Exports a runtime‑friendly graph for CPU/GPU inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57525d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python \"$repo_root/scripts/export_onnx.py\" \\\n",
    "  --config \"$CFG\" \\\n",
    "  --out \"/content/nexus_emb_240m_nsa.onnx\" \\\n",
    "  --seq_len 128\n",
    "\n",
    "import os\n",
    "print(\"ONNX exists:\", os.path.exists(\"/content/nexus_emb_240m_nsa.onnx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d0c4d9",
   "metadata": {},
   "source": [
    "## 5) Quick embedding demo\n",
    "Encodes a few sentences and prints cosine similarities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36be052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, json\n",
    "import sys\n",
    "sys.path.append(repo_root)\n",
    "from transformers import AutoTokenizer\n",
    "from src.model import NexusEmb240MNSA\n",
    "import json\n",
    "\n",
    "cfg = json.load(open(CFG))\n",
    "tok = AutoTokenizer.from_pretrained(SPM, use_fast=False, trust_remote_code=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = NexusEmb240MNSA(cfg).to(device).eval()\n",
    "\n",
    "def embed(texts, max_len=128):\n",
    "    with torch.no_grad():\n",
    "        enc = tok(texts, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "        emb, *_ = model(enc[\"input_ids\"].to(device))\n",
    "        return emb.cpu().numpy()\n",
    "\n",
    "A = [\"BTC funding rate spikes with open interest rise.\",\n",
    "     \"ENTSO-E publishes European grid load datasets.\"]\n",
    "B = [\"Open interest changes often drive funding rate changes.\",\n",
    "     \"European grid load data is available via ENTSO-E datasets.\"]\n",
    "\n",
    "Ea = embed(A); Eb = embed(B)\n",
    "\n",
    "def cos(a,b): return (a*b).sum(-1)/(np.linalg.norm(a,axis=-1)*np.linalg.norm(b,axis=-1)+1e-9)\n",
    "print(\"cos(A[0],B[0]) =\", float(cos(Ea[:1], Eb[:1])))\n",
    "print(\"cos(A[1],B[1]) =\", float(cos(Ea[1:2], Eb[1:2])))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
